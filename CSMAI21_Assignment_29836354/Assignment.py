# -*- coding: utf-8 -*-
"""Assignment_for_upload.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1F49nuVY-Da30Ft20R1lmnxnLH4BAgOCd?usp=sharing
"""


import pandas as pd
import numpy as np
import matplotlib.pyplot as plt 
import plotly.express as px
import matplotlib.colors as colors
from sklearn.model_selection import train_test_split
# logistic regression
from sklearn.linear_model import LogisticRegression
# SVM
from sklearn.svm import SVC
# decision tree virtualization tool
from dtreeviz.trees import dtreeviz
# StandardScaler
from sklearn.preprocessing import StandardScaler
# Function to measure model accuracy is introduced
from sklearn.metrics import mean_squared_error, r2_score
# import plot_confusion_matrix
from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay
# PCA
from sklearn import decomposition
# mdscuda
from mdscuda import MDS, mds_fit, minkowski_pairs
# Cross Val score
from sklearn.model_selection import cross_val_score
from sklearn import tree
import itertools
import time
import seaborn as sns
sns.set(style="white")
sns.set(style="whitegrid", color_codes=True)

"""# 1 Data visualisation, preprocessing, feature selection

## 1.1 Gathering Data
"""

spambase = pd.read_csv('https://datahub.io/machine-learning/spambase/r/spambase.csv')

"""## 1.2 Preprocessing Data

Then we need to check the dataset.
"""

spambase.head()

print(spambase.shape)
print(list(spambase.columns))

"""Check the whole dataset whether has Null and missing values."""

spambase.isnull().values.any()

spambase.isna().values.any()

"""This dataset do not these values.

## 1.3 Data exploration
"""

spambase['class'].value_counts()

# spam (1) or not (0)
sns.countplot(x = 'class', data = spambase, palette='hls')

# spam (1) or not (0)
# count the number of spam and not spam
count_spam = len(spambase[spambase['class']==1])
count_no_spam = len(spambase[spambase['class']==0])

# calculate percentage of each type and print them.
pct_of_spam = count_spam/(count_no_spam+count_spam)
print("percentage of type spam", pct_of_spam*100)

pct_of_no_spam = count_no_spam/(count_no_spam+count_spam)
print("percentage of type no spam", pct_of_no_spam*100)

"""We can calculate the classification mean of other classification variables to understand our data in more detail."""

spambase.groupby("class").mean()

"""## 1.4 Feature Selection"""

spambase.drop(columns=["word_freq_george", "word_freq_650"], axis =1, inplace=True)

# Based on the features, we select the input elements and targets.
X = spambase.iloc[:,0:55]
print(X)

y = spambase.iloc[:,55]
print(y)

"""## 1.5 Data visualisation"""

spambase.describe()

"""## 1.5.1 Scatter Plot"""

# https://matplotlib.org/stable/api/_as_gen/matplotlib.pyplot.scatter.html
spambase.plot.scatter(x='capital_run_length_average', y='capital_run_length_total', c='class', alpha = 0.5, cmap='viridis')

"""## 1.5.2 Decision Tree"""

from sklearn.tree import DecisionTreeClassifier
clf = DecisionTreeClassifier(random_state=0, splitter="best", max_depth=3).fit(X,y)

# https://github.com/parrt/dtreeviz
viz = dtreeviz(clf, X, y,
                target_name="class",
                feature_names=list(spambase),
                class_names=['not spam', 'spam']
                )

viz

from sklearn.inspection import permutation_importance


# get the feature name of dataframe(Columns Names)
feature_names = [f"{i}" for i in X]

# Associating feature names with the importance of the feature.
forest_importances = pd.Series(clf.feature_importances_, index=feature_names)

# split the data into train set and test set
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=0)

# Permutation importance for feature evaluation
result = permutation_importance(
    clf, X_train, y_train, n_repeats=10, random_state=42, n_jobs=2
)

fig, ax = plt.subplots()
forest_importances.plot.bar(yerr=result.importances_std, ax=ax)
ax.set_title("Feature importances using MDI")
ax.set_ylabel("Mean decrease in impurity")
fig.tight_layout()

"""## 1.5.3 Visualize the more importance dimensions"""

fig = px.scatter_matrix(
    spambase,
    dimensions=["word_freq_remove", "word_freq_hpl", "word_freq_lab", "char_freq_%24"],
    color="class"
)
fig.update_traces(diagonal_visible=False)
fig.show()

"""## 1.5.3 PCA

2D PCA Scatter Plot
"""

# set the components to 2 because we need a 2D plot.
pca_2D = decomposition.PCA(n_components=2)
X_pca = pca_2D.fit_transform(X)

fig = px.scatter(X_pca, x=0, y=1, color=spambase['class'])
fig.show()

"""3D PCA Scatter Plot"""

# Build the PCA model
pca_3D = decomposition.PCA(n_components=3)

# make the PCA model fit the feature set
components = pca_3D.fit_transform(X)

# Percentage of variance explained by each of the selected components.
total_var = pca_3D.explained_variance_ratio_.sum() * 100

fig = px.scatter_3d(
    components, x=0, y=1, z=2, color=spambase['class'],
    title=f'Total Explained Variance: {total_var:.2f}%',
    labels={'0': 'PC 1', '1': 'PC 2', '2': 'PC 3'}
)
fig.show()

"""## 1.5.4 MDS"""

from sklearn.preprocessing import MinMaxScaler
scaler = MinMaxScaler()
X_scaled = scaler.fit_transform(X)

from mdscuda import MDS, mds_fit, minkowski_pairs

# this returns a matrix of pairwise distances in longform
DELTA = minkowski_pairs(X_scaled, sqform = False)

x = mds_fit(DELTA, n_dims = 2, verbosity = 1)

colors = ['red','green']
plt.rcParams['figure.figsize'] = [7, 7]
plt.rc('font', size=14)


for i in np.unique(y):
  subset = x[y == i]
  
  a = [row[0] for row in subset]
  b = [row[1] for row in subset]
  plt.scatter(a,b,c=colors[i],label=y[i])
plt.legend()
plt.show()

"""# 2 logistic regression

## 2.1 Buile the model
"""

spambase = pd.read_csv('https://datahub.io/machine-learning/spambase/r/spambase.csv')

spambase.drop(columns=["word_freq_george", "word_freq_650"], axis =1, inplace=True)

# Based on the features, we select the input elements and targets.
X = spambase.iloc[:,0:55]


y = spambase.iloc[:,55]

# split the data into train set and test set
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=0)

scaler = StandardScaler().fit(X_train)
X_train = pd.DataFrame(scaler.transform(X_train), index=y_train)
X_test = pd.DataFrame(scaler.transform(X_test), index=y_test)

# iter should bigger than 1000, otherwise the lbfgs failed to converge
LR = LogisticRegression(multi_class='ovr', solver='lbfgs', max_iter=10000).fit(X_train, y_train)

"""## 2.2 Prediction and Evaluation"""

# Train the model using the training sets
LR_score = LR.score(X_test, y_test)
print('The model score is: ', LR_score)

# Make predictions using the testing set
y_pred = LR.predict(X_test)
print(y_pred, y_pred.shape)

# The coefficients
print("Coefficients: \n", LR.coef_)
# The mean squared error
print("Mean squared error: %.2f" % mean_squared_error(y_test, y_pred))
# The coefficient of determination: 1 is perfect prediction
print("Coefficient of determination: %.2f" % r2_score(y_test, y_pred))

# https://scikit-learn.org/stable/modules/generated/sklearn.metrics.ConfusionMatrixDisplay.html
cm = confusion_matrix(y_test, y_pred, labels=LR.classes_)
disp = ConfusionMatrixDisplay(confusion_matrix=cm,  display_labels=LR.classes_)
disp.plot()
plt.show()

"""## 2.3 Hyperparameter Tuning

### 2.3.1 k-fold crossValidation

we use 10-fold crossvalidation here.
"""

from sklearn.model_selection import cross_val_score
LR_scores = cross_val_score(LR, X, y, cv=10, scoring='f1')
LR_scores

# Mean of scores and 95% confidence interval of scores:
print("Accuracy: %0.2f (+/- %0.2f)" % (LR_scores.mean(), LR_scores.std() * 2))

"""### 2.3.2 Hyperparameter adjustment

#### 2.3.2.1 test different solver
"""

# lbfgs as solver.
LR_newton_cg = LogisticRegression(multi_class='ovr', solver='newton-cg', max_iter=10000).fit(X_train, y_train)
print('score for solver= newton-cg is: ', LR_newton_cg.score(X_test,y_test))

# liblinear as solver.
LR_liblinear = LogisticRegression(multi_class='ovr', solver='liblinear', max_iter=10000).fit(X_train, y_train)
print('score for solver= liblinear is: ', LR_liblinear.score(X_test,y_test))

# sag as solver.
LR_sag = LogisticRegression(multi_class='ovr', solver='sag', max_iter=10000).fit(X_train, y_train)
print('score for solver= sag is: ', LR_sag.score(X_test,y_test))

# sag as solver.
LR_saga = LogisticRegression(multi_class='ovr', solver='saga', max_iter=10000).fit(X_train, y_train)
print('score for solver= saga is: ', LR_saga.score(X_test,y_test))

"""#### 2.3.2.2 test different lose function

Use 'sage' as  solver because it suppose "l1", "l2", "elasticnet" and none.


https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LogisticRegression.html#sklearn.linear_model.LogisticRegression.score
"""

LR_l1 = LogisticRegression(multi_class='ovr', penalty='l1', solver='saga', max_iter=10000).fit(X_train, y_train)
print('score for penalty= l1 is: ', LR_l1.score(X_test,y_test))

LR_l2 = LogisticRegression(multi_class='ovr', penalty='l2', solver='saga', max_iter=10000).fit(X_train, y_train)
print('score for penalty= l2 is: ', LR_l2.score(X_test,y_test))

LR_none = LogisticRegression(multi_class='ovr', penalty='none', solver='saga', max_iter=10000).fit(X_train, y_train)
print('score for penalty= l2 is: ', LR_none.score(X_test,y_test))

# combine l1 and l2 together with 50% each.
LR_elasticnet = LogisticRegression(multi_class='ovr', penalty='elasticnet', solver='saga', l1_ratio=0.5, max_iter=10000).fit(X_train, y_train)
print('score for penalty= l2 is: ', LR_elasticnet.score(X_test,y_test))

"""# 3 SVM

## 3.1 Scale the Data
"""

spambase = pd.read_csv('https://datahub.io/machine-learning/spambase/r/spambase.csv')

spambase.drop(columns=["word_freq_george", "word_freq_650"], axis =1, inplace=True)

# Based on the features, we select the input elements and targets.
X = spambase.iloc[:,0:55]


y = spambase.iloc[:,55]

X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=0)

scaler = StandardScaler().fit(X_train)
X_train = pd.DataFrame(scaler.transform(X_train), index=y_train)
X_test = pd.DataFrame(scaler.transform(X_test), index=y_test)

"""## 3.2 Build a linear SVM"""

svc = SVC(kernel='linear', gamma='auto').fit(X_train, y_train)
print('SVM Accuracy: {acc:.4f}'.format(acc=svc.score(X_test, y_test)))

"""## 3.3 cross validation"""

X_std = pd.DataFrame(scaler.transform(X), index=y)

from sklearn.model_selection import cross_val_score
svc_scores = cross_val_score(svc, X_std, y, cv=10, scoring='f1')
svc_scores

# Mean of scores and 95% confidence interval of scores:
print("Accuracy: %0.2f (+/- %0.2f)" % (svc_scores.mean(), svc_scores.std() * 2))

"""## 3.4 Plot the ROC Curve"""

from sklearn.metrics import plot_roc_curve
plot_roc_curve(svc, X_test, y_test) 
plt.show()

"""## 3.5 Confusion Matrix"""

cnf_matrix = confusion_matrix(y_test, y_pred=svc.predict(X_test))

def plot_confusion_matrix(cm, classes, title='Confusion matrix', cmap='viridis'):
    plt.figure(figsize=(8,8))
    plt.imshow(cm, interpolation='nearest', cmap=cmap)
    plt.title(title, fontsize=28)
    plt.colorbar()
    tick_marks = np.arange(len(classes))
    plt.xticks(tick_marks, classes, rotation=45, fontsize=12)
    plt.yticks(tick_marks, classes, fontsize=12)

    thresh = cm.max() / 2.
    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):
        plt.text(j, i, cm[i, j],
                 horizontalalignment="center",
                 color="white" if cm[i, j] > thresh else "black", fontsize=24)

    plt.tight_layout()
    plt.ylabel('True label', fontsize=18)
    plt.xlabel('Predicted label', fontsize=18)
    plt.show()

plot_confusion_matrix(cnf_matrix, classes=('not_spam','spam'), title='Confusion Matrix')

"""# 4 Neural Network

## 4.1 Preparing Data
"""

spambase = pd.read_csv('https://datahub.io/machine-learning/spambase/r/spambase.csv')

spambase.drop(columns=["word_freq_george", "word_freq_650"], axis =1, inplace=True)

# Based on the features, we select the input elements and targets.
X = spambase.iloc[:,0:55]
y = spambase.iloc[:,55]

# split the data into train set and test set
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=0)

scaler = StandardScaler().fit(X_train)
X_train = pd.DataFrame(scaler.transform(X_train), index=y_train)
X_test = pd.DataFrame(scaler.transform(X_test), index=y_test)

"""## 4.2 Create the Model"""

from tensorflow.keras.models import Sequential
from keras.layers import Dense, Dropout
from tensorflow.keras.utils import plot_model

model = Sequential()
model.add(Dense(55, input_dim=55, activation='relu'))
model.add(Dense(55, activation='relu'))
model.add(Dropout(0.5))
model.add(Dense(55, activation='relu'))
model.add(Dropout(0.5))
model.add(Dense(55, activation='relu'))
model.add(Dropout(0.5))
model.add(Dense(55, activation='relu'))
model.add(Dropout(0.5))
model.add(Dense(55, activation='relu'))
model.add(Dropout(0.5))
model.add(Dense(55, activation='relu'))
model.add(Dropout(0.5))
model.add(Dense(55, activation='relu'))
model.add(Dropout(0.5))
model.add(Dense(1, activation='sigmoid'))
model.compile(loss='binary_crossentropy', optimizer='rmsprop', metrics='accuracy')
model.fit(X_train, y_train, batch_size=1024, epochs=1000, verbose=0)    # if you want to see the verbose log, you can change the "verbose='auto'"
model.summary()

"""## 4.3 Test the Model"""

results = model.evaluate(X_test, y_test, batch_size=512)
print("test loss, test acc:", results)

"""## 4.4 10-fold cross-validation"""

# binary classification NN model
def create_BCNN():
  # create model
  model = Sequential()
  model.add(Dense(55, input_dim=55, activation='relu'))
  model.add(Dense(55, activation='relu'))
  model.add(Dropout(0.5))
  model.add(Dense(55, activation='relu'))
  model.add(Dropout(0.5))
  model.add(Dense(55, activation='relu'))
  model.add(Dropout(0.5))
  model.add(Dense(55, activation='relu'))
  model.add(Dropout(0.5))
  model.add(Dense(55, activation='relu'))
  model.add(Dropout(0.5))
  model.add(Dense(55, activation='relu'))
  model.add(Dropout(0.5))
  model.add(Dense(55, activation='relu'))
  model.add(Dropout(0.5))
  model.add(Dense(1, activation='sigmoid'))
  # Compile model
  model.compile(loss='binary_crossentropy', optimizer='rmsprop', metrics='accuracy')
  return model

# Cross Val score
from sklearn.model_selection import cross_val_score
from keras.wrappers.scikit_learn import KerasClassifier
from sklearn.pipeline import Pipeline
from sklearn.model_selection import StratifiedKFold

# evaluate baseline model with standardized dataset
estimators = []
estimators.append(('standardize', StandardScaler()))
estimators.append(('mlp', KerasClassifier(build_fn=create_BCNN, epochs=500, batch_size=1024, verbose=0)))
pipeline = Pipeline(estimators)
kfold = StratifiedKFold(n_splits=10, shuffle=True)
results = cross_val_score(pipeline, X, y, cv=kfold)
print("Standardized: %.2f%% (%.2f%%)" % (results.mean()*100, results.std()*100))

"""# 5 Compare different model"""

spambase = pd.read_csv('https://datahub.io/machine-learning/spambase/r/spambase.csv')

spambase.drop(columns=["word_freq_george", "word_freq_650"], axis =1, inplace=True)

# Based on the features, we select the input elements and targets.
X = spambase.iloc[:,0:55]


y = spambase.iloc[:,55]

# split the data into train set and test set
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.3, random_state = 0)

scaler = StandardScaler().fit(X_train)
X_train = pd.DataFrame(scaler.transform(X_train), index=y_train)
X_test = pd.DataFrame(scaler.transform(X_test), index=y_test)

results = pd.DataFrame()
time_consumption = []

start = time.time()
results['logical_regression'] = LR.predict(X_test)
end = time.time()
time_consumption.append(end - start)

start = time.time()
results['SVC'] = svc.predict(X_test)
end = time.time()
time_consumption.append(end - start)

start = time.time()
results['Neural_Network'] = np.around(model.predict(X_test)).reshape(-1)
end = time.time()
time_consumption.append(end - start)

evaluations = pd.DataFrame()
from sklearn.metrics import *
for i in range(0, results.shape[1]):
    evaluation = {"precision": precision_score(y_test, results.iloc[:,i]), 
                  "recall": recall_score(y_test, results.iloc[:,i]), 
                  "accuracy": accuracy_score(y_test, results.iloc[:,i]), 
                  "f1": f1_score(y_test, results.iloc[:,i])}
    evaluations = evaluations.append(evaluation, ignore_index=True)
evaluations.rename(index=dict(zip(range(0, evaluations.shape[0]), 
                                  list(results.columns))),inplace=True)

evaluations.insert(0, 'time/s', time_consumption)

evaluations